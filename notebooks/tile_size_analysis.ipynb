{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12165c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn import svm\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "import pickle\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0220a03",
   "metadata": {},
   "source": [
    "## Process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "47616ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(features_path, runtimes_path):\n",
    "\n",
    "    features_df = pd.read_csv(features_path)\n",
    "    runtimes_df = pd.read_csv(runtimes_path)\n",
    "\n",
    "    # clean up some generation artifacts and get average runtimes\n",
    "    runtimes_df['uniqueFilename'] = runtimes_df.uniqueFilename.str.rstrip('.out')\n",
    "    runtimes_df = runtimes_df[runtimes_df.uniqueFilename.str.endswith(\"_0\")==False]\n",
    "    runtimes_df['avgRuntime'] = runtimes_df[['run1','run2','run3','run4']].mean(axis=1)\n",
    "    features_df = features_df[features_df.uniqueFilename.str.endswith(\"_0\")==False]\n",
    "    features_df = features_df[features_df.uniqueFilename.str.endswith(\"_0\")==False]\n",
    "\n",
    "    # merge the features and average runtimes together\n",
    "    merged_df = features_df.merge(runtimes_df[['uniqueFilename', 'avgRuntime']])\n",
    "\n",
    "    # get the fastest tile size for each unique loop\n",
    "    merged_df['uniqueLoopId'] = merged_df.uniqueFilename.str.split(pat='_').str[:3].str.join('_')\n",
    "    merged_df = merged_df.sort_values(['uniqueLoopId','avgRuntime'],ascending=True).groupby('uniqueLoopId').head(1)\n",
    "\n",
    "    # drop programs that predict tile size 0\n",
    "    # merged_df = merged_df[merged_df.tileSize != 1]\n",
    "\n",
    "    # keep only programs that tile the innermost loop\n",
    "    # merged_df = merged_df[(merged_df.distToDominatingLoop == 1) | (merged_df.distToDominatingLoop == 2)]\n",
    "    merged_df = merged_df[(merged_df.distToDominatingLoop == 1)]\n",
    "\n",
    "    merged_df.info()\n",
    "    merged_df.groupby('tileSize').count()\n",
    "    # print(plot_data.isnull().sum())\n",
    "    # sns.pairplot(merged_df.iloc[:, 3:10])\n",
    "    # plt.show()\n",
    "    \n",
    "    return merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a3364e17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../tiled_polybench/features.csv\n",
      "../tiled_polybench/runtimes.csv\n",
      "../tiled_polybench_lin_alg/features.csv\n",
      "../tiled_polybench_lin_alg/runtimes.csv\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 117 entries, 598 to 856\n",
      "Data columns (total 12 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   uniqueFilename        117 non-null    object \n",
      " 1   rootFilename          117 non-null    object \n",
      " 2   tileSize              117 non-null    int64  \n",
      " 3   readInvariant         117 non-null    int64  \n",
      " 4   readPrefetched        117 non-null    int64  \n",
      " 5   readNonPrefetched     117 non-null    int64  \n",
      " 6   writeInvariant        117 non-null    int64  \n",
      " 7   writePrefetched       117 non-null    int64  \n",
      " 8   writeNonPrefetched    117 non-null    int64  \n",
      " 9   distToDominatingLoop  117 non-null    int64  \n",
      " 10  avgRuntime            117 non-null    float64\n",
      " 11  uniqueLoopId          117 non-null    object \n",
      "dtypes: float64(1), int64(8), object(3)\n",
      "memory usage: 11.9+ KB\n"
     ]
    }
   ],
   "source": [
    "!ls ../tiled_polybench/features.csv\n",
    "!ls ../tiled_polybench/runtimes.csv\n",
    "!ls ../tiled_polybench_lin_alg/features.csv\n",
    "!ls ../tiled_polybench_lin_alg/runtimes.csv\n",
    "\n",
    "# features_path = os.path.expanduser(\"../tiled_polybench_lin_alg/features.csv\")\n",
    "# runtimes_path = os.path.expanduser(\"../tiled_polybench_lin_alg/runtimes.csv\")\n",
    "features_path = os.path.expanduser(\"../tiled_polybench/features.csv\")\n",
    "runtimes_path = os.path.expanduser(\"../tiled_polybench/runtimes_trimmed.csv\")\n",
    "\n",
    "merged_df = process_data(features_path, runtimes_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bf03cf6",
   "metadata": {},
   "source": [
    "## Train models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a800b5f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model_to_file(model, filename):\n",
    "    with open(filename, 'wb') as file:\n",
    "        pickle.dump(model, file)\n",
    "        \n",
    "def load_model_from_file(filename):\n",
    "    with open(filename, 'rb') as file:\n",
    "        return pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f92360a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    uniqueFilename rootFilename  tileSize  readInvariant  readPrefetched  \\\n",
      "448     3mm_99_2_1          3mm         1              1               1   \n",
      "70   symm_81_2_128         symm       128              1               0   \n",
      "576    syrk_77_7_1         syrk         1              1               2   \n",
      "\n",
      "     readNonPrefetched  writeInvariant  writePrefetched  writeNonPrefetched  \\\n",
      "448                  1               1                0                   0   \n",
      "70                   4               0                0                   1   \n",
      "576                  0               1                0                   0   \n",
      "\n",
      "     distToDominatingLoop  avgRuntime uniqueLoopId  \n",
      "448                     1   32.539447     3mm_99_2  \n",
      "70                      1   28.433557    symm_81_2  \n",
      "576                     1    4.751532    syrk_77_7  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 35 entries, 1669 to 1785\n",
      "Data columns (total 7 columns):\n",
      " #   Column                Non-Null Count  Dtype\n",
      "---  ------                --------------  -----\n",
      " 0   readInvariant         35 non-null     int64\n",
      " 1   readPrefetched        35 non-null     int64\n",
      " 2   readNonPrefetched     35 non-null     int64\n",
      " 3   writeInvariant        35 non-null     int64\n",
      " 4   writePrefetched       35 non-null     int64\n",
      " 5   writeNonPrefetched    35 non-null     int64\n",
      " 6   distToDominatingLoop  35 non-null     int64\n",
      "dtypes: int64(7)\n",
      "memory usage: 2.2 KB\n"
     ]
    }
   ],
   "source": [
    "# remove our 5 test benchmarks\n",
    "print(merged_df[(merged_df['uniqueLoopId']=='syrk_77_7') |\n",
    "                (merged_df['uniqueLoopId']=='3mm_99_2') |\n",
    "                (merged_df['uniqueLoopId']=='symm_81_2')])\n",
    "merged_df = merged_df[(merged_df['uniqueLoopId']!='syrk_77_7') &\n",
    "                      #(merged_df['uniqueLoopId']!='syr2k_81_7') &\n",
    "                      #(merged_df['uniqueLoopId']!='2mm_94_2') &\n",
    "                      (merged_df['uniqueLoopId']!='3mm_99_2') &\n",
    "                      (merged_df['uniqueLoopId']!='symm_81_2')]\n",
    "\n",
    "# prep data for training\n",
    "X = merged_df.iloc[:, 3:10]\n",
    "#X = (X-X.mean())/X.std()\n",
    "y = merged_df.tileSize\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.3, random_state=1)\n",
    "\n",
    "X_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fe6d2037",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The r2 is:  0.00039281402156210454\n",
      "The rmse is:  88.72314483148281\n",
      "[68.4653673  59.30451587 59.30451587 68.4653673  59.30451587 59.30451587\n",
      " 72.59961015 54.72409016 59.30451587 64.0803404  59.30451587 77.37543468\n",
      " 59.30451587 59.30451587 59.30451587 54.72409016 68.01918444 73.43659064\n",
      " 54.72409016 59.30451587 59.30451587 63.88494159 77.37543468 59.30451587\n",
      " 59.30451587 68.4653673  91.95680441 59.30451587 59.30451587 63.88494159\n",
      " 59.30451587 54.72409016 59.30451587 59.30451587 59.30451587]\n",
      "[ 64   1   8 256  64 256 128   1   4   1   4   1  16   8   1  32   1  64\n",
      "   1   1  16 256   1  16   1 128   1   8  32 256   4   1 256 128   4]\n"
     ]
    }
   ],
   "source": [
    "# linear regression\n",
    "\n",
    "lin_reg = LinearRegression(positive=True)\n",
    "lin_reg.fit(X_train,y_train)\n",
    "predictions = lin_reg.predict(X_test)\n",
    "r2 = r2_score(y_test, predictions)\n",
    "rmse = mean_squared_error(y_test, predictions, squared=False)\n",
    "\n",
    "print('The r2 is: ', r2)\n",
    "print('The rmse is: ', rmse)\n",
    "print(predictions)\n",
    "print(y_test.to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f2c4b1cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.34285714285714286\n",
      "[  4   1 256   4 256 256   1   1   8   1   8   1 256 256 256   1   1  16\n",
      "   1   1   8   1   1   8   1  64 256 256 256   1   8   1 256 256 256]\n",
      "[ 64   1   8 256  64 256 128   1   4   1   4   1  16   8   1  32   1  64\n",
      "   1   1  16 256   1  16   1 128   1   8  32 256   4   1 256 128   4]\n"
     ]
    }
   ],
   "source": [
    "# random forest\n",
    "\n",
    "forest = RandomForestClassifier(n_estimators=500, random_state=888)\n",
    "forest.fit(X_train,y_train)\n",
    "predictions = forest.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\", metrics.accuracy_score(y_test, predictions))\n",
    "print(predictions)\n",
    "print(y_test.to_numpy())\n",
    "\n",
    "save_model_to_file(forest, \"../models/rand_forest.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dfa881ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.2857142857142857\n",
      "[  4  64 256   4 256 256  16   1   8   1   8   1 256 256 256   1   1  16\n",
      "   1   1   8   1   1   8  64   4 256 256 256   1   8   1 256 256 256]\n",
      "[ 64   1   8 256  64 256 128   1   4   1   4   1  16   8   1  32   1  64\n",
      "   1   1  16 256   1  16   1 128   1   8  32 256   4   1 256 128   4]\n"
     ]
    }
   ],
   "source": [
    "# gradient boosted tree\n",
    "\n",
    "boost = GradientBoostingClassifier(n_estimators=1000, learning_rate=0.5, max_depth=1, random_state=8)\n",
    "boost.fit(X_train,y_train)\n",
    "predictions = boost.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\", metrics.accuracy_score(y_test, predictions))\n",
    "print(predictions)\n",
    "print(y_test.to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d255c328",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The r2 is:  -0.3143179554103184\n",
      "The rmse is:  101.73548572476079\n",
      "[6.83845314 5.65662943 8.71676033 6.83845314 8.71676033 8.71676033\n",
      " 6.444041   7.36721058 8.10000004 8.84920183 8.10000004 7.05607473\n",
      " 8.71676033 8.71676033 8.71676033 7.36721058 5.33214708 9.16903857\n",
      " 7.36721058 4.87732452 8.10000004 8.1        7.05607473 8.10000004\n",
      " 5.65662943 6.38534076 8.74008333 8.71676033 8.71676033 8.1\n",
      " 8.10000004 6.22477878 8.71676033 8.71676033 8.71676033]\n",
      "[ 64   1   8 256  64 256 128   1   4   1   4   1  16   8   1  32   1  64\n",
      "   1   1  16 256   1  16   1 128   1   8  32 256   4   1 256 128   4]\n"
     ]
    }
   ],
   "source": [
    "# support vector machine regression\n",
    "\n",
    "support = svm.SVR()\n",
    "support.fit(X_train,y_train)\n",
    "predictions = support.predict(X_test)\n",
    "r2 = r2_score(y_test, predictions)\n",
    "rmse = mean_squared_error(y_test, predictions, squared=False)\n",
    "\n",
    "print('The r2 is: ', r2)\n",
    "print('The rmse is: ', rmse)\n",
    "print(predictions)\n",
    "print(y_test.to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a0daf0c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.14285714285714285\n",
      "[  4  64   4   4   4   4  64  32   8 128   8 128   4   4   4  32   1 128\n",
      "  32   1   8   4 128   8  64  64 128   4   4   4   8   1   4   4   4]\n",
      "[ 64   1   8 256  64 256 128   1   4   1   4   1  16   8   1  32   1  64\n",
      "   1   1  16 256   1  16   1 128   1   8  32 256   4   1 256 128   4]\n"
     ]
    }
   ],
   "source": [
    "# support vector machine classifier\n",
    "\n",
    "support = svm.SVC(random_state=8, class_weight='balanced')\n",
    "support.fit(X_train,y_train)\n",
    "predictions = support.predict(X_test)\n",
    "r2 = r2_score(y_test, predictions)\n",
    "rmse = mean_squared_error(y_test, predictions, squared=False)\n",
    "\n",
    "print(\"Accuracy:\", metrics.accuracy_score(y_test, predictions))\n",
    "print(predictions)\n",
    "print(y_test.to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7cef25da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.34285714285714286\n",
      "[  4   1 256   4 256 256   1   1   8   1   8   1 256 256 256   1   1  16\n",
      "   1   1   8   1   1   8   1  64 256 256 256   1   8   1 256 256 256]\n",
      "[ 64   1   8 256  64 256 128   1   4   1   4   1  16   8   1  32   1  64\n",
      "   1   1  16 256   1  16   1 128   1   8  32 256   4   1 256 128   4]\n"
     ]
    }
   ],
   "source": [
    "# multi-layer perceptron\n",
    "\n",
    "mlp = MLPClassifier(random_state=8, max_iter=10000, hidden_layer_sizes=(30,))\n",
    "mlp.fit(X_train,y_train)\n",
    "predictions = mlp.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\", mlp.score(X_test, y_test))\n",
    "print(predictions)\n",
    "print(y_test.to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "33e0cc11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the best performing models\n",
    "forest = RandomForestClassifier(n_estimators=500, random_state=888)\n",
    "forest.fit(X,y)\n",
    "boost = GradientBoostingClassifier(n_estimators=1000, learning_rate=0.5, max_depth=1, random_state=8)\n",
    "boost.fit(X,y)\n",
    "support = svm.SVC(random_state=8, class_weight='balanced')\n",
    "support.fit(X,y)\n",
    "mlp = MLPClassifier(random_state=8, max_iter=10000, hidden_layer_sizes=(30,))\n",
    "mlp.fit(X,y)\n",
    "\n",
    "save_model_to_file(forest, \"../models/boosted_tree.pkl\")\n",
    "save_model_to_file(forest, \"../models/rand_forest.pkl\")\n",
    "save_model_to_file(forest, \"../models/svm.pkl\")\n",
    "save_model_to_file(forest, \"../models/mlp.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
