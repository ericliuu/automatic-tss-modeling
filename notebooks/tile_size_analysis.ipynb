{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12165c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn import svm\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "import pickle\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d72f2a0",
   "metadata": {},
   "source": [
    "## Process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "47616ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(features_path, runtimes_path):\n",
    "\n",
    "    features_df = pd.read_csv(features_path)\n",
    "    runtimes_df = pd.read_csv(runtimes_path)\n",
    "\n",
    "    # clean up some generation artifacts and get average runtimes\n",
    "    runtimes_df['uniqueFilename'] = runtimes_df.uniqueFilename.str.rstrip('.out')\n",
    "    runtimes_df = runtimes_df[runtimes_df.uniqueFilename.str.endswith(\"_0\")==False]\n",
    "    runtimes_df['avgRuntime'] = runtimes_df[['run1','run2','run3','run4']].mean(axis=1)\n",
    "    features_df = features_df[features_df.uniqueFilename.str.endswith(\"_0\")==False]\n",
    "    features_df = features_df[features_df.uniqueFilename.str.endswith(\"_0\")==False]\n",
    "\n",
    "    # merge the features and average runtimes together\n",
    "    merged_df = features_df.merge(runtimes_df[['uniqueFilename', 'avgRuntime']])\n",
    "\n",
    "    # get the fastest tile size for each unique loop\n",
    "    merged_df['uniqueLoopId'] = merged_df.uniqueFilename.str.split(pat='_').str[:3].str.join('_')\n",
    "    merged_df = merged_df.sort_values(['uniqueLoopId','avgRuntime'],ascending=True).groupby('uniqueLoopId').head(1)\n",
    "\n",
    "    # drop programs that predict tile size 0\n",
    "    # merged_df = merged_df[merged_df.tileSize != 1]\n",
    "\n",
    "    # keep only programs that tile the innermost loop\n",
    "    # merged_df = merged_df[(merged_df.distToDominatingLoop == 1) | (merged_df.distToDominatingLoop == 2)]\n",
    "    merged_df = merged_df[(merged_df.distToDominatingLoop == 1)]\n",
    "\n",
    "    merged_df.info()\n",
    "    merged_df.groupby('tileSize').count()\n",
    "    # print(plot_data.isnull().sum())\n",
    "    # sns.pairplot(merged_df.iloc[:, 3:10])\n",
    "    # plt.show()\n",
    "    \n",
    "    return merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3364e17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../tiled_polybench/features.csv\n",
      "../tiled_polybench/runtimes.csv\n",
      "../tiled_polybench_lin_alg/features.csv\n",
      "../tiled_polybench_lin_alg/runtimes.csv\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 117 entries, 598 to 856\n",
      "Data columns (total 12 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   uniqueFilename        117 non-null    object \n",
      " 1   rootFilename          117 non-null    object \n",
      " 2   tileSize              117 non-null    int64  \n",
      " 3   readInvariant         117 non-null    int64  \n",
      " 4   readPrefetched        117 non-null    int64  \n",
      " 5   readNonPrefetched     117 non-null    int64  \n",
      " 6   writeInvariant        117 non-null    int64  \n",
      " 7   writePrefetched       117 non-null    int64  \n",
      " 8   writeNonPrefetched    117 non-null    int64  \n",
      " 9   distToDominatingLoop  117 non-null    int64  \n",
      " 10  avgRuntime            117 non-null    float64\n",
      " 11  uniqueLoopId          117 non-null    object \n",
      "dtypes: float64(1), int64(8), object(3)\n",
      "memory usage: 11.9+ KB\n"
     ]
    }
   ],
   "source": [
    "!ls ../tiled_polybench/features.csv\n",
    "!ls ../tiled_polybench/runtimes.csv\n",
    "!ls ../tiled_polybench_lin_alg/features.csv\n",
    "!ls ../tiled_polybench_lin_alg/runtimes.csv\n",
    "\n",
    "# features_path = os.path.expanduser(\"../tiled_polybench_lin_alg/features.csv\")\n",
    "# runtimes_path = os.path.expanduser(\"../tiled_polybench_lin_alg/runtimes.csv\")\n",
    "features_path = os.path.expanduser(\"../tiled_polybench/features.csv\")\n",
    "runtimes_path = os.path.expanduser(\"../tiled_polybench/runtimes_trimmed.csv\")\n",
    "\n",
    "merged_df = process_data(features_path, runtimes_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d216d945",
   "metadata": {},
   "source": [
    "## Train models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7da9668a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model_to_file(model, filename):\n",
    "    with open(filename, 'wb') as file:\n",
    "        pickle.dump(model, file)\n",
    "        \n",
    "def load_model_from_file(filename):\n",
    "    with open(filename, 'rb') as file:\n",
    "        return pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f92360a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 36 entries, 120 to 1609\n",
      "Data columns (total 7 columns):\n",
      " #   Column                Non-Null Count  Dtype\n",
      "---  ------                --------------  -----\n",
      " 0   readInvariant         36 non-null     int64\n",
      " 1   readPrefetched        36 non-null     int64\n",
      " 2   readNonPrefetched     36 non-null     int64\n",
      " 3   writeInvariant        36 non-null     int64\n",
      " 4   writePrefetched       36 non-null     int64\n",
      " 5   writeNonPrefetched    36 non-null     int64\n",
      " 6   distToDominatingLoop  36 non-null     int64\n",
      "dtypes: int64(7)\n",
      "memory usage: 2.2 KB\n"
     ]
    }
   ],
   "source": [
    "# prep data for training\n",
    "X = merged_df.iloc[:, 3:10]\n",
    "#X = (X-X.mean())/X.std()\n",
    "y = merged_df.tileSize\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.3, random_state=1)\n",
    "\n",
    "X_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3d15ded9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The r2 is:  0.0637199153030793\n",
      "The rmse is:  85.40026777069802\n",
      "[ 40.80493451  57.98982863  40.80493451  63.63251934  63.63251934\n",
      "  40.80493451  40.92869782  63.63251934  63.63251934  63.63251934\n",
      "  63.63251934  63.63251934  63.63251934  63.63251934  80.75553181\n",
      "  40.80493451 109.28768899  63.63251934  58.05171029  63.63251934\n",
      "  40.80493451  40.92869782  57.92794698  86.46010417 109.28768899\n",
      "  63.63251934  57.98982863  63.63251934  63.63251934 109.28768899\n",
      "  40.86681617  63.63251934  63.63251934  63.63251934  63.63251934\n",
      "  63.63251934]\n",
      "[  1   1   1   1 128  32  64   8   4  16   1   4   8  16 128   1 128 256\n",
      " 256  64   1 256   1   1  64 256   1  16   1 256   1 128   8  32   4   4]\n"
     ]
    }
   ],
   "source": [
    "# linear regression\n",
    "\n",
    "lin_reg = LinearRegression(positive=True)\n",
    "lin_reg.fit(X_train,y_train)\n",
    "predictions = lin_reg.predict(X_test)\n",
    "r2 = r2_score(y_test, predictions)\n",
    "rmse = mean_squared_error(y_test, predictions, squared=False)\n",
    "\n",
    "print('The r2 is: ', r2)\n",
    "print('The rmse is: ', rmse)\n",
    "print(predictions)\n",
    "print(y_test.to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0b172bd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.25\n",
      "[  1   1   1   1 256 128  16 256   8 256 256 256 256   8   1 128  64 256\n",
      " 128 256 128   1   1 256   4   8   1   8   1   4   1 256 256 256   8 256]\n",
      "[  1   1   1   1 128  32  64   8   4  16   1   4   8  16 128   1 128 256\n",
      " 256  64   1 256   1   1  64 256   1  16   1 256   1 128   8  32   4   4]\n"
     ]
    }
   ],
   "source": [
    "# random forest\n",
    "\n",
    "forest = RandomForestClassifier(n_estimators=500, random_state=888)\n",
    "forest.fit(X_train,y_train)\n",
    "predictions = forest.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\", metrics.accuracy_score(y_test, predictions))\n",
    "print(predictions)\n",
    "print(y_test.to_numpy())\n",
    "\n",
    "save_model_to_file(forest, \"../models/rand_forest.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8d7d5113",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.3055555555555556\n",
      "[  1   1   1   1 256   1  16 256   8 256 256 256 256   8  16   1   1 256\n",
      "  64 256   1   1   1 256   4   8   1   8   1   4   1 256 256 256   8 256]\n",
      "[  1   1   1   1 128  32  64   8   4  16   1   4   8  16 128   1 128 256\n",
      " 256  64   1 256   1   1  64 256   1  16   1 256   1 128   8  32   4   4]\n"
     ]
    }
   ],
   "source": [
    "# gradient boosted tree\n",
    "\n",
    "boost = GradientBoostingClassifier(n_estimators=1000, learning_rate=0.5, max_depth=1, random_state=8)\n",
    "boost.fit(X_train,y_train)\n",
    "predictions = boost.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\", metrics.accuracy_score(y_test, predictions))\n",
    "print(predictions)\n",
    "print(y_test.to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3e697aa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The r2 is:  -0.3533088697442057\n",
      "The rmse is:  102.67265762947108\n",
      "[4.36115225 3.91183252 7.79337925 2.81595809 9.33662737 6.41872565\n",
      " 6.52987927 9.33662737 8.00000004 9.33662737 9.33662737 9.33662737\n",
      " 9.33662737 8.00000004 4.69990322 6.41872565 5.01630568 9.33662737\n",
      " 5.55768283 9.33662737 6.41872565 5.77203881 2.60114212 5.2174131\n",
      " 6.86801603 8.00000004 3.91183252 8.00000004 3.53901509 6.86801603\n",
      " 7.24530487 9.33662737 9.33662737 9.33662737 8.00000004 9.33662737]\n",
      "[  1   1   1   1 128  32  64   8   4  16   1   4   8  16 128   1 128 256\n",
      " 256  64   1 256   1   1  64 256   1  16   1 256   1 128   8  32   4   4]\n"
     ]
    }
   ],
   "source": [
    "# support vector machine regression\n",
    "\n",
    "support = svm.SVR()\n",
    "support.fit(X_train,y_train)\n",
    "predictions = support.predict(X_test)\n",
    "r2 = r2_score(y_test, predictions)\n",
    "rmse = mean_squared_error(y_test, predictions, squared=False)\n",
    "\n",
    "print('The r2 is: ', r2)\n",
    "print('The rmse is: ', rmse)\n",
    "print(predictions)\n",
    "print(y_test.to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fa6f9f1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.16666666666666666\n",
      "[  1 128 128   1 256  32 128 256   8 256 256 256 256   8   1  32  64 256\n",
      " 128 256  32 128   1 256 256   8 128   8  64 256 128 256 256 256   8 256]\n",
      "[  1   1   1   1 128  32  64   8   4  16   1   4   8  16 128   1 128 256\n",
      " 256  64   1 256   1   1  64 256   1  16   1 256   1 128   8  32   4   4]\n"
     ]
    }
   ],
   "source": [
    "# support vector machine classifier\n",
    "\n",
    "support = svm.SVC(random_state=8, class_weight='balanced')\n",
    "support.fit(X_train,y_train)\n",
    "predictions = support.predict(X_test)\n",
    "r2 = r2_score(y_test, predictions)\n",
    "rmse = mean_squared_error(y_test, predictions, squared=False)\n",
    "\n",
    "print(\"Accuracy:\", metrics.accuracy_score(y_test, predictions))\n",
    "print(predictions)\n",
    "print(y_test.to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8dc9f28d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.3055555555555556\n",
      "[  1   1   1   1 256   1  16 256   8 256 256 256 256   8   1   1  64 256\n",
      " 128 256   1   1   1 256   4   8   1   8   1   4   1 256 256 256   8 256]\n",
      "[  1   1   1   1 128  32  64   8   4  16   1   4   8  16 128   1 128 256\n",
      " 256  64   1 256   1   1  64 256   1  16   1 256   1 128   8  32   4   4]\n"
     ]
    }
   ],
   "source": [
    "# multi-layer perceptron\n",
    "\n",
    "mlp = MLPClassifier(random_state=8, max_iter=10000, hidden_layer_sizes=(30,))\n",
    "mlp.fit(X_train,y_train)\n",
    "predictions = mlp.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\", mlp.score(X_test, y_test))\n",
    "print(predictions)\n",
    "print(y_test.to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0ee98141",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the best performing models\n",
    "forest = RandomForestClassifier(n_estimators=500, random_state=888)\n",
    "forest.fit(X,y)\n",
    "boost = GradientBoostingClassifier(n_estimators=1000, learning_rate=0.5, max_depth=1, random_state=8)\n",
    "boost.fit(X,y)\n",
    "support = svm.SVC(random_state=8, class_weight='balanced')\n",
    "support.fit(X,y)\n",
    "mlp = MLPClassifier(random_state=8, max_iter=10000, hidden_layer_sizes=(30,))\n",
    "mlp.fit(X,y)\n",
    "\n",
    "save_model_to_file(forest, \"../models/boosted_tree.pkl\")\n",
    "save_model_to_file(forest, \"../models/rand_forest.pkl\")\n",
    "save_model_to_file(forest, \"../models/svm.pkl\")\n",
    "save_model_to_file(forest, \"../models/mlp.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
