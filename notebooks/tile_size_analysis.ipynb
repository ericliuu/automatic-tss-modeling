{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12165c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn import svm\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "import pickle\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35ccceac",
   "metadata": {},
   "source": [
    "## Process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "47616ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(features_path, runtimes_path):\n",
    "\n",
    "    features_df = pd.read_csv(features_path)\n",
    "    runtimes_df = pd.read_csv(runtimes_path)\n",
    "\n",
    "    # clean up some generation artifacts and get average runtimes\n",
    "    runtimes_df['uniqueFilename'] = runtimes_df.uniqueFilename.str.rstrip('.out')\n",
    "    runtimes_df = runtimes_df[runtimes_df.uniqueFilename.str.endswith(\"_0\")==False]\n",
    "    runtimes_df['avgRuntime'] = runtimes_df[['run1','run2','run3','run4']].mean(axis=1)\n",
    "    features_df = features_df[features_df.uniqueFilename.str.endswith(\"_0\")==False]\n",
    "    features_df = features_df[features_df.uniqueFilename.str.endswith(\"_0\")==False]\n",
    "\n",
    "    # merge the features and average runtimes together\n",
    "    merged_df = features_df.merge(runtimes_df[['uniqueFilename', 'avgRuntime']])\n",
    "\n",
    "    # get the fastest tile size for each unique loop\n",
    "    merged_df['uniqueLoopId'] = merged_df.uniqueFilename.str.split(pat='_').str[:3].str.join('_')\n",
    "    merged_df = merged_df.sort_values(['uniqueLoopId','avgRuntime'],ascending=True).groupby('uniqueLoopId').head(1)\n",
    "\n",
    "    # drop programs that predict tile size 1\n",
    "    # merged_df = merged_df[merged_df.tileSize != 1]\n",
    "\n",
    "    # keep only programs that tile their own dominating loop\n",
    "    # merged_df = merged_df[(merged_df.distToDominatingLoop == 1)]\n",
    "\n",
    "    merged_df.info()\n",
    "    merged_df.groupby('tileSize').count()\n",
    "    \n",
    "    return merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3364e17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 168 entries, 586 to 856\n",
      "Data columns (total 12 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   uniqueFilename        168 non-null    object \n",
      " 1   rootFilename          168 non-null    object \n",
      " 2   tileSize              168 non-null    int64  \n",
      " 3   readInvariant         168 non-null    int64  \n",
      " 4   readPrefetched        168 non-null    int64  \n",
      " 5   readNonPrefetched     168 non-null    int64  \n",
      " 6   writeInvariant        168 non-null    int64  \n",
      " 7   writePrefetched       168 non-null    int64  \n",
      " 8   writeNonPrefetched    168 non-null    int64  \n",
      " 9   distToDominatingLoop  168 non-null    int64  \n",
      " 10  avgRuntime            168 non-null    float64\n",
      " 11  uniqueLoopId          168 non-null    object \n",
      "dtypes: float64(1), int64(8), object(3)\n",
      "memory usage: 17.1+ KB\n"
     ]
    }
   ],
   "source": [
    "# features_path = os.path.expanduser(\"../tiled_polybench_lin_alg/features.csv\")\n",
    "# runtimes_path = os.path.expanduser(\"../tiled_polybench_lin_alg/runtimes.csv\")\n",
    "# features_path = os.path.expanduser(\"../tiled_polybench/features.csv\")\n",
    "# runtimes_path = os.path.expanduser(\"../tiled_polybench/runtimes_trimmed.csv\")\n",
    "\n",
    "merged_df = process_data(features_path, runtimes_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1ecdb90",
   "metadata": {},
   "source": [
    "## Train models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c355d2cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model_to_file(model, filename):\n",
    "    with open(filename, 'wb') as file:\n",
    "        pickle.dump(model, file)\n",
    "        \n",
    "def load_model_from_file(filename):\n",
    "    with open(filename, 'rb') as file:\n",
    "        return pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f92360a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prep data for training\n",
    "X = merged_df.iloc[:, 3:10]\n",
    "y = merged_df.tileSize\n",
    "\n",
    "# train and test set for final evaluation\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2, random_state=8)\n",
    "\n",
    "# train and validation for tuning\n",
    "X_train_valid, X_test_valid, y_train_valid, y_test_valid = train_test_split(\n",
    "        X_train, y_train, stratify=y_train, test_size=0.3, random_state=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c08e0cdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The r2 is:  0.015438306894459908\n",
      "The rmse is:  88.10093546295434\n",
      "[ 52.53729187  69.93290521  62.0589901   62.0589901   62.0589901\n",
      "  69.93290521  84.43065367  69.93290521  62.0589901   52.53729187\n",
      "  52.53729187  60.41120698  69.93290521  88.16750099  52.53729187\n",
      "  52.53729187  62.0589901   76.55673856  62.0589901   85.26963611\n",
      "  43.82439432  69.93290521  69.93290521  69.93290521  69.93290521\n",
      "  88.16750099  35.95047921  35.95047921  69.93290521  43.82439432\n",
      "  44.66337676  62.0589901  102.69543122  62.0589901   62.0589901\n",
      "  69.93290521  62.0589901   69.93290521  69.93290521  62.0589901\n",
      "  69.93290521]\n",
      "[  4   1 256  32   8   1   4   8 256  64 128   8  16   1   1 256  16   1\n",
      "  64   4   1   8  32 256 128 256   1   1 128  32   1 256 128   1  16  64\n",
      "  16   8  64 128   8]\n"
     ]
    }
   ],
   "source": [
    "# linear regression\n",
    "\n",
    "lin_reg = LinearRegression(positive=True)\n",
    "lin_reg.fit(X_train_valid,y_train_valid)\n",
    "predictions = lin_reg.predict(X_test_valid)\n",
    "r2 = r2_score(y_test_valid, predictions)\n",
    "rmse = mean_squared_error(y_test_valid, predictions, squared=False)\n",
    "\n",
    "print('The r2 is: ', r2)\n",
    "print('The rmse is: ', rmse)\n",
    "print(predictions)\n",
    "print(y_test_valid.to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6bab4914",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.2926829268292683\n",
      "[ 32   8   8 256 256   8   1   8 256  64  64 128  16   1   1   1   8 128\n",
      " 256 128 128   8  16   8  16   1   1   1  16   1   1 256  64 256 256   8\n",
      " 256   8  16 256  16]\n",
      "[  4   1 256  32   8   1   4   8 256  64 128   8  16   1   1 256  16   1\n",
      "  64   4   1   8  32 256 128 256   1   1 128  32   1 256 128   1  16  64\n",
      "  16   8  64 128   8]\n"
     ]
    }
   ],
   "source": [
    "# random forest\n",
    "\n",
    "forest = RandomForestClassifier(n_estimators=500, random_state=888)\n",
    "forest.fit(X_train_valid,y_train_valid)\n",
    "predictions = forest.predict(X_test_valid)\n",
    "\n",
    "print(\"Accuracy:\", metrics.accuracy_score(y_test_valid, predictions))\n",
    "print(predictions)\n",
    "print(y_test_valid.to_numpy())\n",
    "\n",
    "save_model_to_file(forest, \"../models/rand_forest.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "095a1408",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.21951219512195122\n",
      "[ 32 256   8 256 256 256   1 256 256  64  64   4  16   1  64  64   8 128\n",
      " 256   8  64 256  16 256  16   1   1   1  16  64   1 256  64 256 256 256\n",
      " 256 256  16 256  16]\n",
      "[  4   1 256  32   8   1   4   8 256  64 128   8  16   1   1 256  16   1\n",
      "  64   4   1   8  32 256 128 256   1   1 128  32   1 256 128   1  16  64\n",
      "  16   8  64 128   8]\n"
     ]
    }
   ],
   "source": [
    "# gradient boosted tree\n",
    "\n",
    "boost = GradientBoostingClassifier(n_estimators=500, learning_rate=0.5, max_depth=1, random_state=8)\n",
    "boost.fit(X_train_valid,y_train_valid)\n",
    "predictions = boost.predict(X_test_valid)\n",
    "\n",
    "print(\"Accuracy:\", metrics.accuracy_score(y_test_valid, predictions))\n",
    "print(predictions)\n",
    "print(y_test_valid.to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "522de6f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The r2 is:  -0.3175395254321467\n",
      "The rmse is:  101.91565005994183\n",
      "[15.9130806  15.61684406 13.84084392 14.21340515 14.21340515 15.61684406\n",
      " 15.6064222  15.61684406 14.21340515 14.14114691 14.14114691 15.48228832\n",
      " 15.89985553 14.88992696 15.54889261 15.54889261 13.84084392 14.78596267\n",
      " 14.21340515 15.46237186 16.00566987 15.61684406 15.89985553 15.61684406\n",
      " 15.89985553 14.88992696 14.58830228 15.38292932 15.89985553 15.56691474\n",
      " 12.65777396 14.21340515 16.85506357 14.21340515 14.21340515 15.61684406\n",
      " 14.21340515 15.61684406 15.89985553 14.21340515 15.89985553]\n",
      "[  4   1 256  32   8   1   4   8 256  64 128   8  16   1   1 256  16   1\n",
      "  64   4   1   8  32 256 128 256   1   1 128  32   1 256 128   1  16  64\n",
      "  16   8  64 128   8]\n"
     ]
    }
   ],
   "source": [
    "# support vector machine regression\n",
    "\n",
    "support = svm.SVR()\n",
    "support.fit(X_train_valid,y_train_valid)\n",
    "predictions = support.predict(X_test_valid)\n",
    "r2 = r2_score(y_test_valid, predictions)\n",
    "rmse = mean_squared_error(y_test_valid, predictions, squared=False)\n",
    "\n",
    "print('The r2 is: ', r2)\n",
    "print('The rmse is: ', rmse)\n",
    "print(predictions)\n",
    "print(y_test_valid.to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3c592f2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.14634146341463414\n",
      "[ 32 256  32   4   4 256  64 256   4  64  64  64  16 256  64  64  32 128\n",
      "   4  64  64 256  16 256  16 256  64   1  16  64   1   4  64   4   4 256\n",
      "   4 256  16   4  16]\n",
      "[  4   1 256  32   8   1   4   8 256  64 128   8  16   1   1 256  16   1\n",
      "  64   4   1   8  32 256 128 256   1   1 128  32   1 256 128   1  16  64\n",
      "  16   8  64 128   8]\n"
     ]
    }
   ],
   "source": [
    "# support vector machine classifier\n",
    "\n",
    "support = svm.SVC(random_state=8, class_weight='balanced')\n",
    "support.fit(X_train_valid,y_train_valid)\n",
    "predictions = support.predict(X_test_valid)\n",
    "r2 = r2_score(y_test_valid, predictions)\n",
    "rmse = mean_squared_error(y_test_valid, predictions, squared=False)\n",
    "\n",
    "print(\"Accuracy:\", metrics.accuracy_score(y_test_valid, predictions))\n",
    "print(predictions)\n",
    "print(y_test_valid.to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "982b3bb9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.3170731707317073\n",
      "[ 32   8   8 256 256   8   1   8 256  64  64   8  16   1   1   1   8 128\n",
      " 256 128 128   8  16   8  16   1   1   1  16   1   1 256  64 256 256   8\n",
      " 256   8  16 256  16]\n",
      "[  4   1 256  32   8   1   4   8 256  64 128   8  16   1   1 256  16   1\n",
      "  64   4   1   8  32 256 128 256   1   1 128  32   1 256 128   1  16  64\n",
      "  16   8  64 128   8]\n"
     ]
    }
   ],
   "source": [
    "# multi-layer perceptron\n",
    "\n",
    "mlp = MLPClassifier(random_state=8, max_iter=10000, hidden_layer_sizes=(30,))\n",
    "mlp.fit(X_train_valid,y_train_valid)\n",
    "predictions = mlp.predict(X_test_valid)\n",
    "\n",
    "print(\"Accuracy:\", mlp.score(X_test_valid, y_test_valid))\n",
    "print(predictions)\n",
    "print(y_test_valid.to_numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7567f19a",
   "metadata": {},
   "source": [
    "## Print test accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c253ac57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy    : 0.14705882352941177\n",
      "Grad-boosted Tree Accuracy: 0.14705882352941177\n",
      "SVM Accuracy              : 0.08823529411764706\n",
      "MLP Accuracy              : 0.11764705882352941\n"
     ]
    }
   ],
   "source": [
    "predictions = forest.predict(X_test)\n",
    "print(\"Random Forest Accuracy    :\", metrics.accuracy_score(y_test, predictions))\n",
    "\n",
    "predictions = boost.predict(X_test)\n",
    "print(\"Grad-boosted Tree Accuracy:\", metrics.accuracy_score(y_test, predictions))\n",
    "\n",
    "predictions = support.predict(X_test)\n",
    "print(\"SVM Accuracy              :\", metrics.accuracy_score(y_test, predictions))\n",
    "\n",
    "predictions = mlp.predict(X_test)\n",
    "print(\"MLP Accuracy              :\", mlp.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26a7c19d",
   "metadata": {},
   "source": [
    "## Save trained models to directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "698929b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # save the best performing models\n",
    "# forest = RandomForestClassifier(n_estimators=500, random_state=888)\n",
    "# forest.fit(X,y)\n",
    "# boost = GradientBoostingClassifier(n_estimators=1000, learning_rate=0.5, max_depth=1, random_state=8)\n",
    "# boost.fit(X,y)\n",
    "# support = svm.SVC(random_state=8, class_weight='balanced')\n",
    "# support.fit(X,y)\n",
    "# mlp = MLPClassifier(random_state=8, max_iter=10000, hidden_layer_sizes=(30,))\n",
    "# mlp.fit(X,y)\n",
    "\n",
    "# save_model_to_file(forest, \"../models/boosted_tree.pkl\")\n",
    "# save_model_to_file(forest, \"../models/rand_forest.pkl\")\n",
    "# save_model_to_file(forest, \"../models/svm.pkl\")\n",
    "# save_model_to_file(forest, \"../models/mlp.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
