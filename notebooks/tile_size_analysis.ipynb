{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12165c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn import svm\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "import pickle\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35ccceac",
   "metadata": {},
   "source": [
    "## Process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "47616ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(features_path, runtimes_path):\n",
    "\n",
    "    features_df = pd.read_csv(features_path)\n",
    "    runtimes_df = pd.read_csv(runtimes_path)\n",
    "\n",
    "    # clean up some generation artifacts and get average runtimes\n",
    "    runtimes_df['uniqueFilename'] = runtimes_df.uniqueFilename.str.rstrip('.out')\n",
    "    runtimes_df = runtimes_df[runtimes_df.uniqueFilename.str.endswith(\"_0\")==False]\n",
    "    runtimes_df['avgRuntime'] = runtimes_df[['run1','run2','run3','run4']].mean(axis=1)\n",
    "    features_df = features_df[features_df.uniqueFilename.str.endswith(\"_0\")==False]\n",
    "    features_df = features_df[features_df.uniqueFilename.str.endswith(\"_0\")==False]\n",
    "\n",
    "    # merge the features and average runtimes together\n",
    "    merged_df = features_df.merge(runtimes_df[['uniqueFilename', 'avgRuntime']])\n",
    "\n",
    "    # get the fastest tile size for each unique loop\n",
    "    merged_df['uniqueLoopId'] = merged_df.uniqueFilename.str.split(pat='_').str[:3].str.join('_')\n",
    "    merged_df = merged_df.sort_values(['uniqueLoopId','avgRuntime'],ascending=True).groupby('uniqueLoopId').head(1)\n",
    "\n",
    "    # drop programs that predict tile size 1\n",
    "    # merged_df = merged_df[merged_df.tileSize != 1]\n",
    "\n",
    "    # keep only programs that tile their own dominating loop\n",
    "    # merged_df = merged_df[(merged_df.distToDominatingLoop == 1)]\n",
    "\n",
    "    merged_df.info()\n",
    "    merged_df.groupby('tileSize').count()\n",
    "    \n",
    "    return merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3364e17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 246 entries, 586 to 856\n",
      "Data columns (total 12 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   uniqueFilename        246 non-null    object \n",
      " 1   rootFilename          246 non-null    object \n",
      " 2   tileSize              246 non-null    int64  \n",
      " 3   readInvariant         246 non-null    int64  \n",
      " 4   readPrefetched        246 non-null    int64  \n",
      " 5   readNonPrefetched     246 non-null    int64  \n",
      " 6   writeInvariant        246 non-null    int64  \n",
      " 7   writePrefetched       246 non-null    int64  \n",
      " 8   writeNonPrefetched    246 non-null    int64  \n",
      " 9   distToDominatingLoop  246 non-null    int64  \n",
      " 10  avgRuntime            246 non-null    float64\n",
      " 11  uniqueLoopId          246 non-null    object \n",
      "dtypes: float64(1), int64(8), object(3)\n",
      "memory usage: 25.0+ KB\n"
     ]
    }
   ],
   "source": [
    "# features_path = os.path.expanduser(\"../tiled_polybench_lin_alg/features.csv\")\n",
    "# runtimes_path = os.path.expanduser(\"../tiled_polybench_lin_alg/runtimes.csv\")\n",
    "features_path = os.path.expanduser(\"../tiled_polybench/features.csv\")\n",
    "runtimes_path = os.path.expanduser(\"../tiled_polybench/runtimes_trimmed.csv\")\n",
    "\n",
    "merged_df = process_data(features_path, runtimes_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1ecdb90",
   "metadata": {},
   "source": [
    "## Train models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c355d2cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model_to_file(model, filename):\n",
    "    with open(filename, 'wb') as file:\n",
    "        pickle.dump(model, file)\n",
    "        \n",
    "def load_model_from_file(filename):\n",
    "    with open(filename, 'rb') as file:\n",
    "        return pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f92360a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prep data for training\n",
    "X = merged_df.iloc[:, 3:10]\n",
    "y = merged_df.tileSize\n",
    "\n",
    "# train and test set for final evaluation\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2, random_state=8)\n",
    "\n",
    "# train and validation for tuning\n",
    "X_train_valid, X_test_valid, y_train_valid, y_test_valid = train_test_split(\n",
    "        X_train, y_train, stratify=y_train, test_size=0.3, random_state=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c08e0cdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The r2 is:  -0.0343478407925073\n",
      "The rmse is:  91.4363784910055\n",
      "[ 54.69301694  74.72957281  74.72957281  54.69301694  54.69301694\n",
      "  73.26799804  63.28065458  39.46176733 119.50227084  63.28065458\n",
      "  76.19114757  81.37318478  54.69301694  66.14193516  54.69301694\n",
      "  28.0128491   54.69301694  54.69301694 127.53263397  54.69301694\n",
      "  74.72957281  61.81907981  66.14193516  79.66390723  54.69301694\n",
      "  54.69301694  66.14193516  73.26799804  81.37318478 116.08371575\n",
      "  40.92334209  81.37318478  66.14193516  92.822103    77.59085339\n",
      "  66.14193516  54.69301694  92.822103    54.69301694  66.14193516\n",
      "  81.37318478  86.17849103  66.14193516  63.28065458  54.69301694\n",
      "  54.69301694  54.69301694  81.37318478  92.822103    66.14193516\n",
      "  54.69301694  40.92334209  28.0128491   66.14193516  66.14193516\n",
      " 119.50227084 108.05335261  86.17849103  92.822103  ]\n",
      "[256  64   1  16 256   1   1 128   4   1 128  64   8  64 128 128  16   4\n",
      " 256 256   4   1   8  16   4   4   1 256  64  32  32   1  16   1  16  32\n",
      " 256 256  32   8   1   8   1   1   1 128  16   8   1 128  64  16   1 256\n",
      "   8  64 256   1   1]\n"
     ]
    }
   ],
   "source": [
    "# linear regression\n",
    "\n",
    "lin_reg = LinearRegression(positive=True)\n",
    "lin_reg.fit(X_train_valid,y_train_valid)\n",
    "predictions = lin_reg.predict(X_test_valid)\n",
    "r2 = r2_score(y_test_valid, predictions)\n",
    "rmse = mean_squared_error(y_test_valid, predictions, squared=False)\n",
    "\n",
    "print('The r2 is: ', r2)\n",
    "print('The rmse is: ', rmse)\n",
    "print(predictions)\n",
    "print(y_test_valid.to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6bab4914",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.1864406779661017\n",
      "[  8  64  64   4   4  16   1   1   4   1   1 256   4   1   4   1   8   4\n",
      "  32   4  64   1  64 128   8   4  64  16 256  16   4 256   1  16  32   1\n",
      "   8  16   8  64 256 128  64   1   1   4   4 256  16   1   4   1   1  64\n",
      "   1  16 256 128  16]\n",
      "[256  64   1  16 256   1   1 128   4   1 128  64   8  64 128 128  16   4\n",
      " 256 256   4   1   8  16   4   4   1 256  64  32  32   1  16   1  16  32\n",
      " 256 256  32   8   1   8   1   1   1 128  16   8   1 128  64  16   1 256\n",
      "   8  64 256   1   1]\n"
     ]
    }
   ],
   "source": [
    "# random forest\n",
    "\n",
    "forest = RandomForestClassifier(n_estimators=500, random_state=888)\n",
    "forest.fit(X_train_valid,y_train_valid)\n",
    "predictions = forest.predict(X_test_valid)\n",
    "\n",
    "print(\"Accuracy:\", metrics.accuracy_score(y_test_valid, predictions))\n",
    "print(predictions)\n",
    "print(y_test_valid.to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "095a1408",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.22033898305084745\n",
      "[  1   1   1   1   1   1   1   1   4   1  64  16   1  16   1   1   1   1\n",
      "  32   1   1   1   1   8   1   1   1   1 256   1   1 256  16  16  16  16\n",
      "   1  16   1   1 256 128   1   1   1   1   1 256  16  16   1   1   1   1\n",
      "  16  16   4 128  16]\n",
      "[256  64   1  16 256   1   1 128   4   1 128  64   8  64 128 128  16   4\n",
      " 256 256   4   1   8  16   4   4   1 256  64  32  32   1  16   1  16  32\n",
      " 256 256  32   8   1   8   1   1   1 128  16   8   1 128  64  16   1 256\n",
      "   8  64 256   1   1]\n"
     ]
    }
   ],
   "source": [
    "# gradient boosted tree\n",
    "\n",
    "boost = GradientBoostingClassifier(n_estimators=500, learning_rate=0.5, max_depth=1, random_state=8)\n",
    "boost.fit(X_train_valid,y_train_valid)\n",
    "predictions = boost.predict(X_test_valid)\n",
    "\n",
    "print(\"Accuracy:\", metrics.accuracy_score(y_test_valid, predictions))\n",
    "print(predictions)\n",
    "print(y_test_valid.to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "522de6f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The r2 is:  -0.3011430246068767\n",
      "The rmse is:  102.5529669686721\n",
      "[13.3983059  15.90032103 15.90032103 13.69099603 13.69099603 15.21364272\n",
      " 14.50122708 14.71946951 16.13863795 14.50122708 17.313872   14.52427437\n",
      " 13.69099603 15.35844292 13.69099603 12.83311413 13.3983059  13.69099603\n",
      " 16.7452067  13.69099603 15.90032103 13.54747522 15.25857385 13.93373205\n",
      " 13.3983059  13.69099603 15.25857385 15.21364272 14.67966712 15.64580112\n",
      " 15.30610971 14.67966712 15.35844292 15.90032085 17.51924266 15.35844292\n",
      " 13.3983059  16.10001525 13.3983059  15.25857385 14.67966712 17.23331077\n",
      " 15.25857385 14.50122708 14.12208336 13.69099603 13.69099603 14.67966712\n",
      " 15.90032085 15.35844292 13.69099603 15.21368496 12.83311413 15.25857385\n",
      " 15.35844292 16.27733744 15.44558473 17.23331077 16.11136022]\n",
      "[256  64   1  16 256   1   1 128   4   1 128  64   8  64 128 128  16   4\n",
      " 256 256   4   1   8  16   4   4   1 256  64  32  32   1  16   1  16  32\n",
      " 256 256  32   8   1   8   1   1   1 128  16   8   1 128  64  16   1 256\n",
      "   8  64 256   1   1]\n"
     ]
    }
   ],
   "source": [
    "# support vector machine regression\n",
    "\n",
    "support = svm.SVR()\n",
    "support.fit(X_train_valid,y_train_valid)\n",
    "predictions = support.predict(X_test_valid)\n",
    "r2 = r2_score(y_test_valid, predictions)\n",
    "rmse = mean_squared_error(y_test_valid, predictions, squared=False)\n",
    "\n",
    "print('The r2 is: ', r2)\n",
    "print('The rmse is: ', rmse)\n",
    "print(predictions)\n",
    "print(y_test_valid.to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3c592f2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.23728813559322035\n",
      "[ 32  64  64   4   4  16   1  32   4   1  64  16   4   8   4  32  32   4\n",
      "  16   4  64   1   8  32  32   4   8  16   4  16  64   4   8   4  16   8\n",
      "  32 256  32   8   4  64   8   1  16   4   4   4   4   8   4  64  32   8\n",
      "   8  16   4  64  16]\n",
      "[256  64   1  16 256   1   1 128   4   1 128  64   8  64 128 128  16   4\n",
      " 256 256   4   1   8  16   4   4   1 256  64  32  32   1  16   1  16  32\n",
      " 256 256  32   8   1   8   1   1   1 128  16   8   1 128  64  16   1 256\n",
      "   8  64 256   1   1]\n"
     ]
    }
   ],
   "source": [
    "# support vector machine classifier\n",
    "\n",
    "support = svm.SVC(random_state=8, class_weight='balanced')\n",
    "support.fit(X_train_valid,y_train_valid)\n",
    "predictions = support.predict(X_test_valid)\n",
    "r2 = r2_score(y_test_valid, predictions)\n",
    "rmse = mean_squared_error(y_test_valid, predictions, squared=False)\n",
    "\n",
    "print(\"Accuracy:\", metrics.accuracy_score(y_test_valid, predictions))\n",
    "print(predictions)\n",
    "print(y_test_valid.to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "982b3bb9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.2542372881355932\n",
      "[  8  16  16   4   4  16   1   1   4   1   1  16   4  16   4   1   8   4\n",
      " 128   4  16   1   8 128   8   4   8  16 256 128   4 256  16  16  16  16\n",
      "   8  16   8   8 256   8   8   1   1   4   4 256  16  16   4   1   1   8\n",
      "  16  16 256   8  16]\n",
      "[256  64   1  16 256   1   1 128   4   1 128  64   8  64 128 128  16   4\n",
      " 256 256   4   1   8  16   4   4   1 256  64  32  32   1  16   1  16  32\n",
      " 256 256  32   8   1   8   1   1   1 128  16   8   1 128  64  16   1 256\n",
      "   8  64 256   1   1]\n"
     ]
    }
   ],
   "source": [
    "# multi-layer perceptron\n",
    "\n",
    "mlp = MLPClassifier(random_state=8, max_iter=10000, hidden_layer_sizes=(30,))\n",
    "mlp.fit(X_train_valid,y_train_valid)\n",
    "predictions = mlp.predict(X_test_valid)\n",
    "\n",
    "print(\"Accuracy:\", mlp.score(X_test_valid, y_test_valid))\n",
    "print(predictions)\n",
    "print(y_test_valid.to_numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebe2a341",
   "metadata": {},
   "source": [
    "## Print test accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eca22fb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy    : 0.22\n",
      "Grad-boosted Tree Accuracy: 0.32\n",
      "SVM Accuracy              : 0.18\n",
      "MLP Accuracy              : 0.3\n"
     ]
    }
   ],
   "source": [
    "predictions = forest.predict(X_test)\n",
    "print(\"Random Forest Accuracy    :\", metrics.accuracy_score(y_test, predictions))\n",
    "\n",
    "predictions = boost.predict(X_test)\n",
    "print(\"Grad-boosted Tree Accuracy:\", metrics.accuracy_score(y_test, predictions))\n",
    "\n",
    "predictions = support.predict(X_test)\n",
    "print(\"SVM Accuracy              :\", metrics.accuracy_score(y_test, predictions))\n",
    "\n",
    "predictions = mlp.predict(X_test)\n",
    "print(\"MLP Accuracy              :\", mlp.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "946df843",
   "metadata": {},
   "source": [
    "## Save trained models to directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "698929b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # save the best performing models\n",
    "# forest = RandomForestClassifier(n_estimators=500, random_state=888)\n",
    "# forest.fit(X,y)\n",
    "# boost = GradientBoostingClassifier(n_estimators=1000, learning_rate=0.5, max_depth=1, random_state=8)\n",
    "# boost.fit(X,y)\n",
    "# support = svm.SVC(random_state=8, class_weight='balanced')\n",
    "# support.fit(X,y)\n",
    "# mlp = MLPClassifier(random_state=8, max_iter=10000, hidden_layer_sizes=(30,))\n",
    "# mlp.fit(X,y)\n",
    "\n",
    "# save_model_to_file(forest, \"../models/boosted_tree.pkl\")\n",
    "# save_model_to_file(forest, \"../models/rand_forest.pkl\")\n",
    "# save_model_to_file(forest, \"../models/svm.pkl\")\n",
    "# save_model_to_file(forest, \"../models/mlp.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
