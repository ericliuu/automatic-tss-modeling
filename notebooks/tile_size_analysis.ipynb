{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12165c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn import svm\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "import pickle\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b1b6b87",
   "metadata": {},
   "source": [
    "## Process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "47616ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(features_path, runtimes_path):\n",
    "\n",
    "    features_df = pd.read_csv(features_path)\n",
    "    runtimes_df = pd.read_csv(runtimes_path)\n",
    "\n",
    "    # clean up some generation artifacts and get average runtimes\n",
    "    runtimes_df['uniqueFilename'] = runtimes_df.uniqueFilename.str.rstrip('.out')\n",
    "    runtimes_df = runtimes_df[runtimes_df.uniqueFilename.str.endswith(\"_0\")==False]\n",
    "    runtimes_df['avgRuntime'] = runtimes_df[['run1','run2','run3','run4']].mean(axis=1)\n",
    "    features_df = features_df[features_df.uniqueFilename.str.endswith(\"_0\")==False]\n",
    "    features_df = features_df[features_df.uniqueFilename.str.endswith(\"_0\")==False]\n",
    "\n",
    "    # merge the features and average runtimes together\n",
    "    merged_df = features_df.merge(runtimes_df[['uniqueFilename', 'avgRuntime']])\n",
    "\n",
    "    # get the fastest tile size for each unique loop\n",
    "    merged_df['uniqueLoopId'] = merged_df.uniqueFilename.str.split(pat='_').str[:3].str.join('_')\n",
    "    merged_df = merged_df.sort_values(['uniqueLoopId','avgRuntime'],ascending=True).groupby('uniqueLoopId').head(1)\n",
    "\n",
    "    # drop programs that predict tile size 0\n",
    "    # merged_df = merged_df[merged_df.tileSize != 1]\n",
    "\n",
    "    # keep only programs that tile the innermost loop\n",
    "    # merged_df = merged_df[(merged_df.distToDominatingLoop == 1) | (merged_df.distToDominatingLoop == 2)]\n",
    "    merged_df = merged_df[(merged_df.distToDominatingLoop == 1)]\n",
    "\n",
    "    merged_df.info()\n",
    "    merged_df.groupby('tileSize').count()\n",
    "    # print(plot_data.isnull().sum())\n",
    "    # sns.pairplot(merged_df.iloc[:, 3:10])\n",
    "    # plt.show()\n",
    "    \n",
    "    return merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3364e17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../tiled_polybench/features.csv\n",
      "../tiled_polybench/runtimes.csv\n",
      "../tiled_polybench_lin_alg/features.csv\n",
      "../tiled_polybench_lin_alg/runtimes.csv\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 117 entries, 598 to 856\n",
      "Data columns (total 12 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   uniqueFilename        117 non-null    object \n",
      " 1   rootFilename          117 non-null    object \n",
      " 2   tileSize              117 non-null    int64  \n",
      " 3   readInvariant         117 non-null    int64  \n",
      " 4   readPrefetched        117 non-null    int64  \n",
      " 5   readNonPrefetched     117 non-null    int64  \n",
      " 6   writeInvariant        117 non-null    int64  \n",
      " 7   writePrefetched       117 non-null    int64  \n",
      " 8   writeNonPrefetched    117 non-null    int64  \n",
      " 9   distToDominatingLoop  117 non-null    int64  \n",
      " 10  avgRuntime            117 non-null    float64\n",
      " 11  uniqueLoopId          117 non-null    object \n",
      "dtypes: float64(1), int64(8), object(3)\n",
      "memory usage: 11.9+ KB\n"
     ]
    }
   ],
   "source": [
    "!ls ../tiled_polybench/features.csv\n",
    "!ls ../tiled_polybench/runtimes.csv\n",
    "!ls ../tiled_polybench_lin_alg/features.csv\n",
    "!ls ../tiled_polybench_lin_alg/runtimes.csv\n",
    "\n",
    "# features_path = os.path.expanduser(\"../tiled_polybench_lin_alg/features.csv\")\n",
    "# runtimes_path = os.path.expanduser(\"../tiled_polybench_lin_alg/runtimes.csv\")\n",
    "features_path = os.path.expanduser(\"../tiled_polybench/features.csv\")\n",
    "runtimes_path = os.path.expanduser(\"../tiled_polybench/runtimes_trimmed.csv\")\n",
    "\n",
    "merged_df = process_data(features_path, runtimes_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51416ec0",
   "metadata": {},
   "source": [
    "## Train models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "80fa4cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model_to_file(model, filename):\n",
    "    with open(filename, 'wb') as file:\n",
    "        pickle.dump(model, file)\n",
    "        \n",
    "def load_model_from_file(filename):\n",
    "    with open(filename, 'rb') as file:\n",
    "        return pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f92360a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prep data for training\n",
    "X = merged_df.iloc[:, 3:10]\n",
    "#X = (X-X.mean())/X.std()\n",
    "y = merged_df.tileSize\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5cc1807b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The r2 is:  0.11846255593325383\n",
      "The rmse is:  87.87142011246108\n",
      "[ 59.73764468  59.73764468  37.95173214  41.80225478  59.73764468\n",
      "  59.73764468 103.30946975  59.73764468  59.73764468  59.73764468\n",
      "  59.73764468  59.73764468  59.73764468  37.95173214 103.30946975\n",
      "  37.95173214  56.28078819 103.30946975  52.43026554  59.73764468\n",
      "  59.73764468  59.73764468  70.36565543  59.73764468]\n",
      "[  8  16   1   1 256   1  64  32   1  64 256 128   4   1 128   1 256 256\n",
      "   1  16   4   8 128   1]\n"
     ]
    }
   ],
   "source": [
    "# linear regression\n",
    "\n",
    "lin_reg = LinearRegression(positive=True)\n",
    "lin_reg.fit(X_train,y_train)\n",
    "predictions = lin_reg.predict(X_test)\n",
    "r2 = r2_score(y_test, predictions)\n",
    "rmse = mean_squared_error(y_test, predictions, squared=False)\n",
    "\n",
    "print('The r2 is: ', r2)\n",
    "print('The rmse is: ', rmse)\n",
    "print(predictions)\n",
    "print(y_test.to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2ca62bc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.3333333333333333\n",
      "[256   8   1   1 256   1   4 256 256 256   8 256 256   1  64   1 128   4\n",
      "   1   8   8 256   1   1]\n",
      "[  8  16   1   1 256   1  64  32   1  64 256 128   4   1 128   1 256 256\n",
      "   1  16   4   8 128   1]\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './models/rand_forest.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [8]\u001b[0m, in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(predictions)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(y_test\u001b[38;5;241m.\u001b[39mto_numpy())\n\u001b[0;32m---> 11\u001b[0m \u001b[43msave_model_to_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mforest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./models/rand_forest.pkl\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [4]\u001b[0m, in \u001b[0;36msave_model_to_file\u001b[0;34m(model, filename)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msave_model_to_file\u001b[39m(model, filename):\n\u001b[0;32m----> 2\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mwb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[1;32m      3\u001b[0m         pickle\u001b[38;5;241m.\u001b[39mdump(model, file)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './models/rand_forest.pkl'"
     ]
    }
   ],
   "source": [
    "# random forest\n",
    "\n",
    "forest = RandomForestClassifier(n_estimators=500, random_state=888)\n",
    "forest.fit(X_train,y_train)\n",
    "predictions = forest.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\", metrics.accuracy_score(y_test, predictions))\n",
    "print(predictions)\n",
    "print(y_test.to_numpy())\n",
    "\n",
    "runtimes_path = os.path.expanduser(\"../tiled_polybench/runtimes_trimmed.csv\")\n",
    "save_model_to_file(forest, \"./models/rand_forest.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c17345",
   "metadata": {},
   "outputs": [],
   "source": [
    "# support vector machine regression\n",
    "\n",
    "support = svm.SVR()\n",
    "support.fit(X_train,y_train)\n",
    "predictions = support.predict(X_test)\n",
    "r2 = r2_score(y_test, predictions)\n",
    "rmse = mean_squared_error(y_test, predictions, squared=False)\n",
    "\n",
    "print('The r2 is: ', r2)\n",
    "print('The rmse is: ', rmse)\n",
    "print(predictions)\n",
    "print(y_test.to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b841b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# support vector machine classifier\n",
    "\n",
    "support = svm.SVC(random_state=8, class_weight='balanced')\n",
    "support.fit(X_train,y_train)\n",
    "predictions = support.predict(X_test)\n",
    "r2 = r2_score(y_test, predictions)\n",
    "rmse = mean_squared_error(y_test, predictions, squared=False)\n",
    "\n",
    "print(\"Accuracy:\", metrics.accuracy_score(y_test, predictions))\n",
    "print(predictions)\n",
    "print(y_test.to_numpy())\n",
    "\n",
    "save_model_to_file(forest, \"models/svm.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96daaba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# multi-layer perceptron\n",
    "\n",
    "mlp = MLPClassifier(random_state=8, max_iter=10000, hidden_layer_sizes=(30,))\n",
    "mlp.fit(X_train,y_train)\n",
    "predictions = mlp.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\", mlp.score(X_test, y_test))\n",
    "print(predictions)\n",
    "print(y_test.to_numpy())\n",
    "\n",
    "save_model_to_file(forest, \"models/mlp.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
